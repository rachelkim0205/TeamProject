{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2601852f-9a9f-4c92-8181-8e9f85f9a321",
   "metadata": {},
   "source": [
    "# Stock Price(QQQ) Prediction Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbae149-5868-4dc1-9e79-78138b61b70a",
   "metadata": {},
   "source": [
    "QQQ is an ETF tracking the NASDAQ-100 Index, bundling major U.S. tech stocks like Apple and Tesla.  \n",
    "With over 50% weighting in the tech sector, it directly mirrors the growth trajectory of technology industries.  \n",
    "While highly volatile due to its tech concentration, it has historically delivered strong long-term returns (~15% annual average).   \n",
    "Short-term performance remains sensitive to interest rate changes and macroeconomic conditions.  \n",
    "\n",
    "For our price prediction project, we'll focus on analyzing tech trends, earnings reports, and Fed policies as key variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7106ad-ff16-44d8-af21-f7cca81d9cd3",
   "metadata": {},
   "source": [
    "## 1. Libraries & APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e404bf-8984-4e23-b121-d8371a7353d4",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/carlmcbrideellis/lstm-time-series-stock-price-prediction-fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727bf760-9d96-452b-995e-ee60f5c70044",
   "metadata": {},
   "outputs": [],
   "source": [
    "python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc489abc-2145-406e-abd8-1efd6c1ff84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8578348-ed54-4813-8057-2cae9185810c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\bpark\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense, Dropout\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[0m\n\u001b[0;32m     86\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     93\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     94\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\bpark\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "import seaborn as sns\n",
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a1215a-ca81-4d2b-846b-6d56d042be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stock dataset install\n",
    "\n",
    "!pip -q install yfinance\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26c7b2e-a36e-4618-9f12-175b5267130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec60e0-7538-4337-8009-4f567219501d",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b885bf46-37c9-4a0f-a6ac-567b7df2f22e",
   "metadata": {},
   "source": [
    "In this project, the goal is short-term prediction, and to avoid overfitting, it was determined that using 5 years of data is appropriate.  \n",
    "Therefore, the period was set from 2020 to 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c5b9ec-27be-4c58-9c74-144e6fb2cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download using yhfinance\n",
    "df= yf.download(\"QQQ\", start=\"2020-01-01\", end=\"2024-12-31\", auto_adjust=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbf3658-bb15-4209-9de8-7c84827d53d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_index to add the data column\n",
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15f20e-7196-4f8e-baae-4ca1a0c649ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df.columns = ['date', 'adj close', 'close', 'high', 'low', 'open', 'volume']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ffb4f-75af-403c-91e7-940307933e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete later\n",
    "#df.to_csv('QQQ adj_close (200101-241231).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10041b41-b416-4bf4-b597-31037b21cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195b74c-c975-4b89-b05c-9d99a41fbd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Null Values:\", df.isnull().values.sum())\n",
    "print(\"NA Values:\", df.isna().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d49f7-199d-4748-a314-95869c406aba",
   "metadata": {},
   "source": [
    "## 3. EDA(Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae0894b-cdd3-49a3-b1cb-61d4d4f02205",
   "metadata": {},
   "source": [
    "### 3.1. Duration of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc939bf-79cf-497d-af1b-2a84d463e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting date: \", df.iat[0, 0])\n",
    "print(\"Ending date: \", df.iat[-1, 0])\n",
    "print(\"Total number of days: \",df.shape[0])\n",
    "print(\"Total number of fields: \",df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3adc7d7-3963-4ef4-9e39-d5ebaa3b553f",
   "metadata": {},
   "source": [
    "### 3.2. Stock Price Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ab166-4e35-4b70-a811-405b9a3cdf92",
   "metadata": {},
   "source": [
    "First, it is necessary to visualize the stock price trends from 2020 to 2024 to intuitively understand the data.  \n",
    "This will help quickly identify trends, volatility, outliers, and specific patterns, providing valuable insights for model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701b688e-b4c0-498b-b724-462376a1cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 5 years of stock price data\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "ax.plot(df['date'], df['close'])\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Closing Price')\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ffb979-b371-4920-8088-acb137ecfbef",
   "metadata": {},
   "source": [
    "Through the above graph, we can understand the overall trend over the past 5 years. Overall, there is an upward trend, but there are sharp declines in the early part of 2020 and between 2022 and 2023. To examine this in more detail, let's look at the graphs for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692396d-d229-4376-8df6-55321f9f10af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 5 years of data using a 3x2 subplot layout\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 8), sharex=False, sharey=True)\n",
    "\n",
    "years = [2020, 2021, 2022, 2023, 2024]\n",
    "\n",
    "# Plot each year's data\n",
    "for i, year in enumerate(years):\n",
    "    row, col = i // 2, i % 2 \n",
    "    df_year = df[df['date'].dt.year == year]\n",
    "    \n",
    "    # Plot only if data is available\n",
    "    if not df_year.empty:\n",
    "        axes[row, col].plot(df_year['date'], df_year['close'])\n",
    "        axes[row, col].set_title(f\"Stock Prices in {year}\")\n",
    "        axes[row, col].set_ylabel(\"Closing Price\")\n",
    "        \n",
    "        # Set X-axis limits from the start to the end of the year\n",
    "        axes[row, col].set_xlim(df_year['date'].min(), df_year['date'].max())\n",
    "\n",
    "# Remove empty subplots if any\n",
    "for i in range(len(years), 6):  \n",
    "    fig.delaxes(axes[i // 2, i % 2])\n",
    "\n",
    "# Automatically adjust X-axis date format\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e88af6f-7c10-4ac5-b1e0-e17ef6a69575",
   "metadata": {},
   "source": [
    "### 📈 Key Events Impacting the Stock Market in 2020, 2022\n",
    "\n",
    "- **2020.02**  \n",
    "**COVID-19 pandemic** broke out, increasing global uncertainty and causing a sharp decline in stock prices.\n",
    "Later, a rebound occurred as government stimulus measures and central bank interest rate cuts helped the stock market recover.\n",
    "\n",
    "- **2022.02**   \n",
    "**Russia vs. Ukraine war** began.\n",
    "Energy and commodity prices soared, leading to worsening global economic inflation.\n",
    "Increased uncertainty caused stock prices to drop.\n",
    "\n",
    "- **2022.03**   \n",
    "**Fed's interest rate hike (0.25%) began**, aimed at controlling inflation, but it negatively impacted the stock market.\n",
    "\n",
    "- **2022.06, 07, 09**   \n",
    "**Fed's interest rate hikes (each 0.75%)** were implemented.\n",
    "The June and July rate hikes especially caused significant market volatility, further deepening the downward trend in the stock market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac1033-2414-4adf-acb2-b65c98d4ee70",
   "metadata": {},
   "source": [
    "### 3.3. Seasonality, Yearly Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64140133-d589-42c6-bf09-df30b914303a",
   "metadata": {},
   "source": [
    "To understand the seasonality, trends, and patterns in the stock market over the past five years, we calculate the monthly and yearly average closing prices.\n",
    "\n",
    "**Seasonality Check**  \n",
    "The stock market can exhibit recurring patterns at specific times of the year. For example, phenomena like the Year-end Rally or low trading volumes during the summer are commonly observed in the market. By calculating the average closing price per month, we can identify which months tend to show bullish or bearish trends.\n",
    "\n",
    "**Yearly Trend Analysis**  \n",
    "To understand the long-term market trends, we conduct a yearly average closing price analysis. This allows us to assess the overall market flow in each year and identify periods of significant volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef135e7-119c-4361-8210-7c01e5137446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the month and year from the 'Date' column\n",
    "df['month'] = df['date'].dt.month\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "\n",
    "# Calculate the mean close price per month\n",
    "monthly_mean = df.groupby(['month'])['close'].mean().reset_index()\n",
    "\n",
    "# Calculate the mean close price per year\n",
    "yearly_mean = df.groupby(['year'])['close'].mean().reset_index()\n",
    "\n",
    "print(\"\\n<Monthly Mean Close Price> \\n\", monthly_mean)\n",
    "print(\"\\n<Yearly Mean Close Price> \\n\", yearly_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375bcf59-218a-4806-8343-93ddc6349585",
   "metadata": {},
   "source": [
    "#### 3.3.1 Seasonality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e1dde-3830-4d4f-ae2b-3c9bc70f52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean close price per month using a Seaborn bar chart\n",
    "ax = sns.barplot(data=monthly_mean, x='month', y='close', hue='month', palette='coolwarm', legend=False)\n",
    "\n",
    "plt.title('Mean Close Price per Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Mean Close Price')\n",
    "\n",
    "# X-axis ticks for each month\n",
    "plt.xticks(range(0, 12), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                                  'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "\n",
    "# Adding the value labels on top of bars\n",
    "for bars in ax.containers:\n",
    "    ax.bar_label(bars, fontsize=8, fmt='%.2f')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb873a6b-b8e5-4d3e-9bec-9d5066f2938f",
   "metadata": {},
   "source": [
    "### 📈 **Monthly Seasonality (Strong Bullish/Bearish Periods)**\n",
    "\n",
    "**Bullish in the Second Half** (July to December)  \n",
    "From June (338) to December (378), a +11.8% increase.  \n",
    "Especially a sharp rise from November (369) to December (378) → aligns with the \"Year-end Rally\" phenomenon.\n",
    "\n",
    "**Volatility in the First Half** (January to March)  \n",
    "From January (320) to March (316), a -1.3% decrease → no sign of the \"January Effect\" (traditionally a bullish January).\n",
    "\n",
    "**Summer Stagnation** (July to September)  \n",
    "From July (355) to September (354), a slight decline of -0.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b946d8f-cf8f-47fd-b4f4-5f926d3e3db7",
   "metadata": {},
   "source": [
    "#### 3.3.2 Yearly Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83953d4-ccc1-43c7-bcba-8736b92ffde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_year= yearly_mean['year'].tolist()\n",
    "\n",
    "# Plot the mean close price per month using a Seaborn bar chart\n",
    "ax = sns.barplot(data=yearly_mean, x='year', y='close', palette='coolwarm', hue = 'year', legend = False)\n",
    "\n",
    "plt.title('Mean Close Price per Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean Close Price')\n",
    "\n",
    "plt.xticks(range(0, len(lst_year)), labels=lst_year)\n",
    "\n",
    "for bars in ax.containers:\n",
    "     ax.bar_label(bars, fontsize=12, fmt='%.2f')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173054d7-c88f-405e-9a3d-5f10d963a59e",
   "metadata": {},
   "source": [
    "### 📊 **Annual Trend (5-Year Long-Term Performance)**\n",
    "\n",
    "Annual Average Return from 2020 to 2024: +16.7% (250 → 464)\n",
    "\n",
    "**2021:** +40.9% (250 → 353) → Tech sector boom\n",
    "\n",
    "**2022:** -12.0% (353 → 310) → Impact of interest rate hikes\n",
    "\n",
    "**2024:** +34.4% (345 → 464) → AI rally driving growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f6dee4-7239-4043-a8a3-dc9a315cbb7b",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a869a-7417-40e0-9bee-34f246d69aba",
   "metadata": {},
   "source": [
    "- Moving Averages (MA): Smooths stock price movements to identify short-term and long-term trends (e.g., 5-day, 20-day, 50-day, 200-day).\n",
    "- Relative Strength Index (RSI): Measures whether a stock is overbought or oversold, reflecting price momentum.\n",
    "- MACD (Moving Average Convergence Divergence): Identifies trend changes and momentum using two moving averages.\n",
    "- Bollinger Bands: Measures price volatility and deviation from the average price.\n",
    "- Volume Volatility: Analyzes the relationship between price and trading volume to predict market movements.\n",
    "- Open-Close Difference: Indicates daily price volatility and potential trend strength.\n",
    "- High-Low Difference: Represents intraday volatility, with larger differences signaling higher fluctuations.\n",
    "- High-Open Difference (High_Open_Diff): Measures how much the high price (high) has increased compared to the opening price (open) during the day.\n",
    "- Low-Close Difference (Low_Close_Diff): Measures how much the closing price (close) has recovered compared to the low price (low) during the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50108c98-3fb9-4e79-b798-c8950281c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Moving Average (MA)\n",
    "df['MA_5'] = df['close'].rolling(window=5).mean()  # 5-day moving average\n",
    "df['MA_20'] = df['close'].rolling(window=20).mean()  # 20-day moving average\n",
    "df['MA_50'] = df['close'].rolling(window=50).mean()  # 50-day moving average\n",
    "\n",
    "# 2. Relative Strength Index (RSI)\n",
    "delta = df['close'].diff()\n",
    "gain = delta.where(delta > 0, 0)\n",
    "loss = -delta.where(delta < 0, 0)\n",
    "avg_gain = gain.rolling(window=14).mean()\n",
    "avg_loss = loss.rolling(window=14).mean()\n",
    "rs = avg_gain / avg_loss\n",
    "df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# 3. MACD (Moving Average Convergence Divergence)\n",
    "df['EMA_12'] = df['close'].ewm(span=12, adjust=False).mean()  # 12-day exponential moving average\n",
    "df['EMA_26'] = df['close'].ewm(span=26, adjust=False).mean()  # 26-day exponential moving average\n",
    "df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
    "\n",
    "# 4. Bollinger Bands\n",
    "df['Bollinger_Upper'] = df['MA_20'] + 2 * df['close'].rolling(window=20).std() \n",
    "df['Bollinger_Lower'] = df['MA_20'] - 2 * df['close'].rolling(window=20).std()\n",
    "\n",
    "# 5. Volume\n",
    "df['Volume_MA_20'] = df['volume'].rolling(window=20).mean()  # 20-day moving average of volume\n",
    "\n",
    "# 6. Open-Close, High-Low Difference\n",
    "df['Open_Close_Diff'] = df['open'] - df['close'] \n",
    "df['High_Low_Diff'] = df['high'] - df['low'] \n",
    "\n",
    "# 8. High-Open Difference, Low-Close Difference\n",
    "df['High_Open_Diff'] = df['high'] - df['open'] \n",
    "df['Low_Close_Diff'] = df['low'] - df['close'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba96e5-0672-493c-b2b8-cd4caa00f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0de57196-e030-44d0-9457-ffbcf252e258",
   "metadata": {},
   "source": [
    "df.ffill(inplace=True) # Missing value correction (moving average & Bollinger bands)\n",
    "df.loc[:, 'RSI'] = df['RSI'].fillna(df['RSI'].mean()) # RSI missing value correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49aef3f-0a90-40ac-a746-ca817e00e596",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989424f7-42da-44bb-bf4e-ceb405bbb192",
   "metadata": {},
   "source": [
    "### 1. Baseline Model for benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb003c-7f12-4ab5-b824-4f64b5d85b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Moving Average Model : Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f56728-31a2-4382-aecc-67d013f9d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 5-day Moving Average (MA_5)\n",
    "df['MA_5'] = df['close'].rolling(window=5).mean()\n",
    "\n",
    "# Use the 5-day Moving Average as the baseline model's prediction\n",
    "# Since we want to predict the next day's closing price, shift the MA_5 by 1 day\n",
    "df['predicted_close_ma'] = df['MA_5'].shift(1)\n",
    "\n",
    "# Remove the NaN values caused by the shift\n",
    "df = df.dropna(subset=['predicted_close_ma'])\n",
    "\n",
    "# Define the features and target for the MA model\n",
    "X_baseline = df[['MA_5']]  # Using the MA_5 as the feature\n",
    "y_baseline = df['close']   # Actual close prices are the target\n",
    "\n",
    "# Train-test split\n",
    "X_train_baseline, X_test_baseline, y_train_baseline, y_test_baseline = train_test_split(X_baseline, y_baseline, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a model (Linear Regression)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "baseline_model = LinearRegression()\n",
    "baseline_model.fit(X_train_baseline, y_train_baseline)\n",
    "\n",
    "# Prediction\n",
    "y_pred_baseline = baseline_model.predict(X_test_baseline)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "mae_baseline = mean_absolute_error(y_test_baseline, y_pred_baseline)\n",
    "print(f\"Baseline MAE (Moving Average): {mae_baseline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d571cd-fc9b-4a12-a3ff-63db85bf40b3",
   "metadata": {},
   "source": [
    "### 2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7dff4-ada8-4e03-96ed-0cc1e8ddc83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "\n",
    "# Fill missing values\n",
    "df.ffill(inplace=True)\n",
    "\n",
    "# Define the features and target variable\n",
    "# Use the technical indicators (excluding date and adj close)\n",
    "features = ['MA_5', 'MA_20', 'MA_50', 'RSI', 'EMA_12', 'EMA_26', 'MACD', 'Bollinger_Upper', 'Bollinger_Lower', \n",
    "            'Volume_MA_20', 'Open_Close_Diff', 'High_Low_Diff', 'High_Open_Diff', 'Low_Close_Diff']\n",
    "target = 'close'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost model (with tuned hyperparameters)\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=1000, #EX\n",
    "    learning_rate=0.01, #EX\n",
    "    max_depth=6, #EX\n",
    "    subsample=0.8,#EX\n",
    "    colsample_bytree=0.8, #EX\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# plot feature importance\n",
    "xgb.plot_importance(model, importance_type='weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e72e2-646f-4abd-af15-a33735453368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Feature Scaling (LSTM에 입력되는 값들은 0~1로 정규화)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# 'close'만 정규화 (타겟만 사용할 예정)\n",
    "scaled_data = scaler.fit_transform(df['close'].values.reshape(-1, 1))\n",
    "\n",
    "# 2. 시계열 데이터 생성 (Window size - 예: 60일)\n",
    "def create_dataset(data, window_size=60):\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i, 0])  # X는 윈도우 크기만큼의 데이터\n",
    "        y.append(data[i, 0])  # y는 다음 날의 종가\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 60  # 60일 데이터를 기반으로 예측\n",
    "X, y = create_dataset(scaled_data, window_size)\n",
    "\n",
    "# 3. 데이터 형태 조정 (LSTM의 입력 형태에 맞게)\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))  # (samples, timesteps, features)\n",
    "\n",
    "# 4. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. LSTM 모델 구성\n",
    "model = Sequential()\n",
    "\n",
    "# LSTM layer\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
    "\n",
    "# LSTM layer\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# 6. 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# 7. 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 8. 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 9. 결과 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test, color='blue', label='Actual Stock Price')\n",
    "plt.plot(y_pred, color='red', label='Predicted Stock Price')\n",
    "plt.title('Stock Price Prediction using LSTM')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 10. 평가 (MAE 계산)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae_lstm = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"LSTM MAE: {mae_lstm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6797e96-93f4-4d80-a18a-4adcafeac6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a430b4-317c-4d94-a897-3f857926821a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
